{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 2: Unsupervised learning\n",
    "In dit deel wordt de K-means clustering methode gebruikt om de categorieën van products en issues te bepalen waartoe de klachten behoren. Deze keer wordt aan unsupervised learning gedaan, wat betekent dat de categorieën niet vooraf bepaald worden, in tegenstelling tot supervised learning. We laten de models dus zelf bepalen wat de onderverdelingen zijn.\n",
    "\n",
    "K-means is een methode die de data opdeelt in k clusters. Initieel worden k punten gekozen als clusters, willekeurig of aan de hand van een algoritme. Vervolgens wordt de cluster waartoe een ander punt behoort bepaald door de afstand van het punt tot het gemiddelde van de cluster. Dit proces wordt verschillende keren herhaald waarna de configuratie met de kleinste totale variantie van de punten in de clusters gekozen wordt als beste configuratie.\n",
    "\n",
    "Een manier om de beste waarde voor k te kiezen is de *elbow method*. Hierbij worden verschillende waarden voor k getest en wordt de verandering in de totale variantie van de data geplot (hoe groter k, hoe kleiner de totale varantie). Deze totale variantie (inertia) is de som van de kwadraten van de afstanden van de punten tot het midden van hun cluster. De beste waarde voor k is dan de 'elleboog' van de geplotte functie. Dit is het punt waar de vermindering van de variantie significant groter is dan die bij het volgende punt.\n",
    "\n",
    "## Inlezen data\n",
    "We beginnen opnieuw met het inlezen van de complaints. Enkel volgende kolommen worden bijgehouden in de complaints dataframe:\n",
    "* Product\n",
    "* Sub-product\n",
    "* Issue\n",
    "* Sub-issue\n",
    "* Consumer complaint narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub_Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub_Issue</th>\n",
       "      <th>Narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Credit monitoring or identity theft protection...</td>\n",
       "      <td>Problem canceling credit monitoring or identif...</td>\n",
       "      <td>I have complained many times that the credit r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>please review the current fraud account and al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt was paid</td>\n",
       "      <td>Called multiple times over the years for a deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other debt</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt was result of identity theft</td>\n",
       "      <td>I sent in a letter to the company to have them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Received unsolicited financial product or insu...</td>\n",
       "      <td>On XX/XX/19 I applied for a Debt Relief Produc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product       Sub_Product  \\\n",
       "0  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "1                                    Debt collection     I do not know   \n",
       "2                                    Debt collection     I do not know   \n",
       "3                                    Debt collection        Other debt   \n",
       "4  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "\n",
       "                                               Issue  \\\n",
       "0  Credit monitoring or identity theft protection...   \n",
       "1                 False statements or representation   \n",
       "2                  Attempts to collect debt not owed   \n",
       "3                  Attempts to collect debt not owed   \n",
       "4                        Improper use of your report   \n",
       "\n",
       "                                           Sub_Issue  \\\n",
       "0  Problem canceling credit monitoring or identif...   \n",
       "1                  Attempted to collect wrong amount   \n",
       "2                                      Debt was paid   \n",
       "3                  Debt was result of identity theft   \n",
       "4  Received unsolicited financial product or insu...   \n",
       "\n",
       "                                           Narrative  \n",
       "0  I have complained many times that the credit r...  \n",
       "1  please review the current fraud account and al...  \n",
       "2  Called multiple times over the years for a deb...  \n",
       "3  I sent in a letter to the company to have them...  \n",
       "4  On XX/XX/19 I applied for a Debt Relief Produc...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "complaints = pd.read_csv('../data/complaints.csv', delimiter=',')\n",
    "complaints = complaints[['Product', 'Sub-product', 'Issue', 'Sub-issue', 'Consumer complaint narrative']].copy()\n",
    "complaints.columns = ['Product', 'Sub_Product', 'Issue', 'Sub_Issue', 'Narrative'] \n",
    "complaints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "De volgende stap is om de data geschikt te maken voor clustering, aan de hand van pre-processing technieken. Dit wordt op dezelfde manier gedaan als in de vorige sprint. We passen onder andere tokenization en stemming (werkwoorden en andere woorden reduceren tot hun stamvorm) toe en we verwijderen stopwoorden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "def processing(string):\n",
    "    # omzetten naar lowercase \n",
    "    string = string.lower()\n",
    "    # alles wat niet gelijk is aan een lowercase of whitespace eruit filteren\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    # alle getallen eruit filteren\n",
    "    string = re.sub(r'[0-9]|,', '', string)\n",
    "    # returns en newlines eruithalen\n",
    "    string = string.replace('\\r', ' ')\n",
    "    string = string.replace('\\n', ' ')\n",
    "    # kaartnummers staan in de tekst als volgt XXX XXX ..., deze eruit filteren\n",
    "    string = re.sub(r'[X|x]{2,}', ' ', string)\n",
    "    # de string splitten om de stopwoorden er afzonderlijk uit te halen\n",
    "    tokens = string.split(' ')\n",
    "    # stopwoorden verwijderen en woorden die bestaan uit maximum 3 karakters weglaten\n",
    "    tokens = [w for w in tokens if w not in ENGLISH_STOP_WORDS and len(w) > 3]\n",
    "    # werkwoord vervoegingen veranderen en woorden reduceren naar stamvorm\n",
    "    result = [SnowballStemmer('english').stem(WordNetLemmatizer().lemmatize(token, pos='v')) for token in tokens]\n",
    "    return ' ' . join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Narrative_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have complained many times that the credit r...</td>\n",
       "      <td>complain time credit report experian inaccur j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>please review the current fraud account and al...</td>\n",
       "      <td>review current fraud account fraudul inquir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Called multiple times over the years for a deb...</td>\n",
       "      <td>call multipl time year debt occur previous mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I sent in a letter to the company to have them...</td>\n",
       "      <td>send letter compani valid debt special attach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>On XX/XX/19 I applied for a Debt Relief Produc...</td>\n",
       "      <td>appli debt relief product account execut expla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Narrative  \\\n",
       "0  I have complained many times that the credit r...   \n",
       "1  please review the current fraud account and al...   \n",
       "2  Called multiple times over the years for a deb...   \n",
       "3  I sent in a letter to the company to have them...   \n",
       "4  On XX/XX/19 I applied for a Debt Relief Produc...   \n",
       "\n",
       "                                 Narrative_processed  \n",
       "0  complain time credit report experian inaccur j...  \n",
       "1        review current fraud account fraudul inquir  \n",
       "2  call multipl time year debt occur previous mar...  \n",
       "3  send letter compani valid debt special attach ...  \n",
       "4  appli debt relief product account execut expla...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints['Narrative_processed'] = complaints['Narrative'].apply(processing)\n",
    "complaints[['Narrative','Narrative_processed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "Om de woorden om te zetten in bruikbare data maken we nieuwe features aan de hand van een CountVectorizer. Deze converteert de token sets naar een ijle matrix van token counts. De matrix is ijl (sparse) omdat de meeste elementen nul zijn of dicht bij nul liggen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, max_df=0.95)\n",
    "X = vectorizer.fit_transform(complaints['Narrative_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)\n",
    "#vectorizer.vocabulary_\n",
    "print('Er zijn %d unieke woorden.' % X.shape[1])\n",
    "# plt.scatter(X[:,0], X[:,1], s=20)\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "Nu kan de K-means methode toegepast worden op de matrix. We beginnen met 100 verschillende waarden voor k uit te testen, om daarna aan de hand van de *elbow method* de beste waarde te kiezen. Initieel worden dus onderverdelingen gemaakt met 1 tot en met 100 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#List voor bijhouden van WCSS (Within-Cluster-Sum-of-Squares):\n",
    "inertia = []\n",
    "k_min = 1\n",
    "k_max = 100\n",
    "for i in range(k_min, k_max):\n",
    "    print(i)\n",
    "    kmeans = KMeans(n_clusters = i, n_jobs = -1)\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De totale varianties van de punten in de clusters per waarde voor k zitten nu in de lijst *inertia*. Dit staat ons toe om deze in een grafiek te zetten en de *elbow* van de functie te vinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(k_min,k_max), inertia, marker='o')\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ...\n",
    "model = KMeans(n_clusters = k, n_jobs = -1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Meest voorkomende woorden per cluster:\")\n",
    "cluster_centers = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for j in cluster_centers[i, :10]:\n",
    "        print(' %s' % terms[j])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusters2D(data, cluster_labels, cluster_centers = None):  \n",
    "    unique_labels = set(cluster_labels)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    \n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            col = [0, 0, 0, 1]        \n",
    "\n",
    "        plt.scatter(data[cluster_labels == k,0],data[cluster_labels == k,1],s=20,c=[col])\n",
    "\n",
    "    if cluster_centers is not None:\n",
    "        plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=250, marker='*', c='red', edgecolor='black')\n",
    "  \n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters = ..., n_jobs = -1)\n",
    "y_km = km.fit_predict(X)\n",
    "plotClusters2D(X,y_km,km.cluster_centers_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
